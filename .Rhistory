train2<-read.csv("pml-training.csv",colClasses=c("classe"="factor","user_name"="factor",rep("numeric",158)))
train2<-read.csv("pml-training.csv",colClasses=c("classe"="factor","user_name"="factor","cvtd_timestamp"="factor","new_window"="factor",rep("numeric",156)))
train2<-read.csv("pml-training.csv",colClasses=c("classe"="factor","user_name"="factor","cvtd_timestamp"="factor","new_window"="factor",rep("numeric",156)))
train2<-read.csv("pml-training.csv",colClasses=c(classe="factor",user_name="factor",cvtd_timestamp="factor",new_window="factor",rep("numeric",156)))
train2<-read.csv("pml-training.csv",colClasses=c(classe="factor",user_name="factor",cvtd_timestamp="factor",new_window="factor"))
train2<-read.csv("pml-training.csv",colClasses=c(classe="factor",user_name="factor",cvtd_timestamp="factor",new_window="factor",rep("numeric",156)))
train3<-train
rbind(train3,test)
?rbind
View(test)
train3<-(train,test)
train3<-rbind(train,test)
train2<-read.csv("pml-training.csv",colClasses=c(classe="factor",user_name="factor",cvtd_timestamp="factor",new_window="factor",rep("numeric",155)))
train2<-read.csv("pml-training.csv",colClasses=c(classe="factor",user_name="factor",cvtd_timestamp="factor",new_window="factor",rep("numeric",156)))
View(train2)
names(train)
train2<-read.csv("pml-training.csv",colClasses=c("classe"="factor","user_name"="factor","cvtd_timestamp"="factor","new_window"="factor",rep("numeric",156)))
train2<-read.csv("pml-training.csv",colClasses=c("classe"="factor","user_name"="factor","new_window"="factor",rep("numeric",156)))
train2<-read.csv("pml-training.csv",colClasses=c("classe"="factor","user_name"="factor","new_window"="factor",rep("numeric",157)))
View(test)
sappy(test,function(x)all(is.na(x)))
sapply(test,function(x)all(is.na(x)))
test2<-test[,colSums(is.na(test)) != nrow(test)]
train2<-train[,colSums(is.na(test)) != nrow(test)]
train<-read.csv("pml-training.csv")
test<-read.csv("pml-testing.csv")
test2<-test[,colSums(is.na(test)) != nrow(test)]
train2<-train[,colSums(is.na(test)) != nrow(test)]
modFit <- train(classe ~ .,method="rf",data=train2)
answers<-predict(modFit2,newdata=test2)
answers<-predict(modFit,newdata=test2)
answers
modFit$finalModel
answers = rep("A", 20)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
setwd("./test")
pml_write_files(answers)
answers<-predict(modFit,newdata=test)
answers
View(train2)
train3<-train2[,c(2,4:60)]
train3<-train2[,c(2,6:60)]
train3<-train2[,c(2,6:60)]
modFit <- train(classe ~ .,method="rf",data=train3)
answers<-predict(modFit,newdata=test)
answers
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
setwd("./test")
pml_write_files(answers)
setwd("./test")
getwd()
setwd("/Users/bn/test")
modFit$finalModel
pairs(train)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
seed.set(33833)
random.seed(33833)
set.seed(33833)
vowel.train
View(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
View(vowel.train)
vowel.test$y<-as.factor(vowel.test$y)
rf<-train(y~.,method='rf', data=vowel.train)
gbm<-train(y~.,method='gbm', data=vowel.train)
rf$finalModel
gbm$finalModel
gbm$error
confusionMatric(gbm, vowel.train$y)
confusionMatrix(gbm, vowel.train$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
predict(rf,newdata=vowel.test)
rf2<-train(y~.,method='rf', training)
rf2<-train(diagnosis~.,method='rf', training)
gbm2<-train(diagnosis~.,method='gbm', training)
lda<-train(diagnosis~.,method='lda', training)
confusionMatrix(lda)
confusionMatrix(gbm2)
confusionMatrix(rf2)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso<-train(CompressiveStrength~.,method='lasso', training)
>plot.enet
?plot.enet
plot.enet(lasso)
lasso$finalModel
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
getwd()
setwd("/users/bn")
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats
install.packages("forecast")
library(forecast)
?bats
bats(tstrain)
?forecast
forecast(bats(tstrain),testing)
t<-bats(tstrain)
forecast(bats(training),testing)
forecast(bats(tstrain),testing#$visitsTumbler)
)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
?e1071
library(e1071)
?e1071
install.packages("devtools")
library(devtools)
devtools::install_github('rstudio/shinyapps')
library(shinyapps)
install.packages(c("boot", "car", "cluster", "codetools", "CORElearn", "dplyr", "knitr", "MASS", "Matrix", "nlme", "Rcpp", "rmarkdown"))
install.packages(c("boot", "car", "cluster", "codetools", "CORElearn",
install.packages(c("boot", "car", "cluster", "codetools", "CORElearn", "dplyr", "knitr", "MASS", "Matrix", "nlme", "Rcpp", "rmarkdown"))
install.packages("shiny")
library(shiny)
runApp("App-1")
runExample("01_hello")
getwd()
for(i in 1:30) {
for(j in 19:19) {
url <- paste(urlbase1, YearIDs[j], urlbase2, TeamIDs[i,2], urlbase3, sep="")
print(url)
download.file(url, paste(TeamIDs[i,1], YearIDs[j], "cpas.json", sep=""))
}
}
##
## NBA Spatial Shooting Data Collection
## Author: Michael Dickey
## Purpose: Scrape JSON data from NBA.com shot charts for each season/team since 1996
## Note: This does take a long time... JSON files will be saved to working directory then converted to a csv
##       file with each team's shots since 1996-97... These csv files must then be concatenated together if data
##       is desired to be in one file. This was not done within R to support lower memory versions of R.
## To span through json files saved from download file command in R, write matrix
## of TeamIDs and YearIDs
TeamIDs <- matrix(nrow = 30, ncol = 2)
colnames(TeamIDs) <- c("Team", "TeamID")
YearIDs <- matrix(nrow = 19, ncol = 1)
colnames(YearIDs) <- "Year/Season"
TeamIDs[1,] <- c("ATL", "1610612737")
TeamIDs[2,] <- c("BOS", "1610612738")
TeamIDs[3,] <- c("BRK", "1610612751")
TeamIDs[4,] <- c("CHI", "1610612741")
TeamIDs[5,] <- c("CLE", "1610612739")
TeamIDs[6,] <- c("DAL", "1610612742")
TeamIDs[7,] <- c("DEN", "1610612743")
TeamIDs[8,] <- c("DET", "1610612765")
TeamIDs[9,] <- c("GSW", "1610612744")
TeamIDs[10,] <- c("HOU", "1610612745")
TeamIDs[11,] <- c("IND", "1610612754")
TeamIDs[12,] <- c("LAC", "1610612746")
TeamIDs[13,] <- c("LAL", "1610612747")
TeamIDs[14,] <- c("MEM", "1610612763")
TeamIDs[15,] <- c("MIA", "1610612748")
TeamIDs[16,] <- c("MIN", "1610612750")
TeamIDs[17,] <- c("MIL", "1610612749")
TeamIDs[18,] <- c("NYK", "1610612752")
TeamIDs[19,] <- c("NOP", "1610612740")
TeamIDs[20,] <- c("OKC", "1610612760")
TeamIDs[21,] <- c("ORL", "1610612753")
TeamIDs[22,] <- c("PHI", "1610612755")
TeamIDs[23,] <- c("PHX", "1610612756")
TeamIDs[24,] <- c("POR", "1610612757")
TeamIDs[25,] <- c("SAC", "1610612758")
TeamIDs[26,] <- c("SAS", "1610612759")
TeamIDs[27,] <- c("TOR", "1610612761")
TeamIDs[28,] <- c("UTA", "1610612762")
TeamIDs[29,] <- c("WAS", "1610612764")
TeamIDs[30,] <- c("CHA", "1610612766")
YearIDs[1,] <- "1996-97"
YearIDs[2,] <- "1997-98"
YearIDs[3,] <- "1998-99"
YearIDs[4,] <- "1999-00"
YearIDs[5,] <- "2000-01"
YearIDs[6,] <- "2001-02"
YearIDs[7,] <- "2002-03"
YearIDs[8,] <- "2003-04"
YearIDs[9,] <- "2004-05"
YearIDs[10,] <- "2005-06"
YearIDs[11,] <- "2006-07"
YearIDs[12,] <- "2007-08"
YearIDs[13,] <- "2008-09"
YearIDs[14,] <- "2009-10"
YearIDs[15,] <- "2010-11"
YearIDs[16,] <- "2011-12"
YearIDs[17,] <- "2012-13"
YearIDs[18,] <- "2013-14"
YearIDs[19,] <- "2014-15"
##Download data files, by going through each url and use the download.file command
## to save to directory
#download.file(url, destfile, method, quiet = FALSE, mode = "w", cacheOK = TRUE,
#extra = getOption("download.file.extra"))
##Example url name from the 1996-97 Vancouver Grizzlies shots:
##http://stats.nba.com/stats/shotchartdetail?Season=1996-97&SeasonType=Regular+Season&
##LeagueID=00&TeamID=1610612763&PlayerID=0&GameID=&Outcome=&Location=&Month=0&SeasonSegment=&
##DateFrom=&DateTo=&OpponentTeamID=0&VsConference=&VsDivision=&Position=&RookieYear=&
##GameSegment=&Period=0&LastNGames=0&ContextFilter=&ContextMeasure=FG_PCT&display-mode=
##performance&zone-mode=zone
urlbase1 <- "http://stats.nba.com/stats/shotchartdetail?Season="
urlbase2 <- "&SeasonType=Playoffs&LeagueID=00&TeamID="
urlbase3 <- "&PlayerID=0&GameID=&Outcome=&Location=&Month=0&SeasonSegment=&DateFrom=&DateTo=&OpponentTeamID=0&VsConference=&VsDivision=&Position=&RookieYear=&GameSegment=&Period=0&LastNGames=0&ContextFilter=&ContextMeasure=FG_PCT&display-mode=performance&zone-mode=zone"
for(i in 1:30) {
for(j in 19:19) {
url <- paste(urlbase1, YearIDs[j], urlbase2, TeamIDs[i,2], urlbase3, sep="")
print(url)
download.file(url, paste(TeamIDs[i,1], YearIDs[j], "cpas.json", sep=""))
}
}
for(i in 1:30) {
teamdata<-matrix(0,ncol=21)
for(j in 19:19) {
filename <- paste(TeamIDs[i,1], YearIDs[j], "cpas.json", sep="")
raw = fromJSON(readLines(filename))
shotdata <- lapply( raw, function(u) lapply(u, function(x) if(is.null(x)) NA else x))
shotdata<-shotdata[[3]]
data2<-shotdata[[1]][[3]]
if(length(data2)==0){
next()}
data <- matrix( nrow=length(data2), ncol=21)
for(k in 1:length(data2)){
for(l in 1:21) {
if(length(data2[[k]][[l]]) == 1) {
data[k,l] <- data2[[k]][[l]]
}
}
}
data[,1]<-YearIDs[j]
colnames(data)<-c("Year","GameID","GameEventID","PlayerID","PlayerName","TeamID","TeamName","Period","MinutesRemaining",
"SecondsRemaining","ShotResult","ActionType","ShotType","ShotZoneBasic","ShotZoneArea","ShotZoneRange",
"ShotDistance","X.Coord","Y.Coord","ShotAttemptedDummy","ShotMadeDummy")
teamdata<-rbind(teamdata,data)
}
write.table(teamdata[-1,], file=paste("Shots",TeamIDs[i,1],"p.csv", sep=""), sep=",",row.names=FALSE)
}
library(RJSONIO)
library(rjson)
library(plyr)
for(i in 1:30) {
teamdata<-matrix(0,ncol=21)
for(j in 19:19) {
filename <- paste(TeamIDs[i,1], YearIDs[j], "cpas.json", sep="")
raw = fromJSON(readLines(filename))
shotdata <- lapply( raw, function(u) lapply(u, function(x) if(is.null(x)) NA else x))
shotdata<-shotdata[[3]]
data2<-shotdata[[1]][[3]]
if(length(data2)==0){
next()}
data <- matrix( nrow=length(data2), ncol=21)
for(k in 1:length(data2)){
for(l in 1:21) {
if(length(data2[[k]][[l]]) == 1) {
data[k,l] <- data2[[k]][[l]]
}
}
}
data[,1]<-YearIDs[j]
colnames(data)<-c("Year","GameID","GameEventID","PlayerID","PlayerName","TeamID","TeamName","Period","MinutesRemaining",
"SecondsRemaining","ShotResult","ActionType","ShotType","ShotZoneBasic","ShotZoneArea","ShotZoneRange",
"ShotDistance","X.Coord","Y.Coord","ShotAttemptedDummy","ShotMadeDummy")
teamdata<-rbind(teamdata,data)
}
write.table(teamdata[-1,], file=paste("Shots",TeamIDs[i,1],"p.csv", sep=""), sep=",",row.names=FALSE)
}
View(teamdata)
## To span through json files saved from download file command in R, write matrix
## of TeamIDs and YearIDs
TeamIDs <- matrix(nrow = 30, ncol = 2)
colnames(TeamIDs) <- c("Team", "TeamID")
YearIDs <- matrix(nrow = 19, ncol = 1)
colnames(YearIDs) <- "Year/Season"
TeamIDs[1,] <- c("ATL", "1610612737")
TeamIDs[2,] <- c("BOS", "1610612738")
TeamIDs[3,] <- c("BRK", "1610612751")
TeamIDs[4,] <- c("CHI", "1610612741")
TeamIDs[5,] <- c("CLE", "1610612739")
TeamIDs[6,] <- c("DAL", "1610612742")
TeamIDs[7,] <- c("DEN", "1610612743")
TeamIDs[8,] <- c("DET", "1610612765")
TeamIDs[9,] <- c("GSW", "1610612744")
TeamIDs[10,] <- c("HOU", "1610612745")
TeamIDs[11,] <- c("IND", "1610612754")
TeamIDs[12,] <- c("LAC", "1610612746")
TeamIDs[13,] <- c("LAL", "1610612747")
TeamIDs[14,] <- c("MEM", "1610612763")
TeamIDs[15,] <- c("MIA", "1610612748")
TeamIDs[16,] <- c("MIN", "1610612750")
TeamIDs[17,] <- c("MIL", "1610612749")
TeamIDs[18,] <- c("NYK", "1610612752")
TeamIDs[19,] <- c("NOP", "1610612740")
TeamIDs[20,] <- c("OKC", "1610612760")
TeamIDs[21,] <- c("ORL", "1610612753")
TeamIDs[22,] <- c("PHI", "1610612755")
TeamIDs[23,] <- c("PHX", "1610612756")
TeamIDs[24,] <- c("POR", "1610612757")
TeamIDs[25,] <- c("SAC", "1610612758")
TeamIDs[26,] <- c("SAS", "1610612759")
TeamIDs[27,] <- c("TOR", "1610612761")
TeamIDs[28,] <- c("UTA", "1610612762")
TeamIDs[29,] <- c("WAS", "1610612764")
TeamIDs[30,] <- c("CHA", "1610612766")
YearIDs[1,] <- "1996-97"
YearIDs[2,] <- "1997-98"
YearIDs[3,] <- "1998-99"
YearIDs[4,] <- "1999-00"
YearIDs[5,] <- "2000-01"
YearIDs[6,] <- "2001-02"
YearIDs[7,] <- "2002-03"
YearIDs[8,] <- "2003-04"
YearIDs[9,] <- "2004-05"
YearIDs[10,] <- "2005-06"
YearIDs[11,] <- "2006-07"
YearIDs[12,] <- "2007-08"
YearIDs[13,] <- "2008-09"
YearIDs[14,] <- "2009-10"
YearIDs[15,] <- "2010-11"
YearIDs[16,] <- "2011-12"
YearIDs[17,] <- "2012-13"
YearIDs[18,] <- "2013-14"
YearIDs[19,] <- "2014-15"
##Download data files, by going through each url and use the download.file command
## to save to directory
#download.file(url, destfile, method, quiet = FALSE, mode = "w", cacheOK = TRUE,
#extra = getOption("download.file.extra"))
##Example url name from the 1996-97 Vancouver Grizzlies shots:
##http://stats.nba.com/stats/shotchartdetail?Season=1996-97&SeasonType=Regular+Season&
##LeagueID=00&TeamID=1610612763&PlayerID=0&GameID=&Outcome=&Location=&Month=0&SeasonSegment=&
##DateFrom=&DateTo=&OpponentTeamID=0&VsConference=&VsDivision=&Position=&RookieYear=&
##GameSegment=&Period=0&LastNGames=0&ContextFilter=&ContextMeasure=FG_PCT&display-mode=
##performance&zone-mode=zone
urlbase1 <- "http://stats.nba.com/stats/shotchartdetail?Season="
urlbase2 <- "&SeasonType=Regular+Season&LeagueID=00&TeamID="
urlbase3 <- "&PlayerID=0&GameID=&Outcome=&Location=&Month=0&SeasonSegment=&DateFrom=&DateTo=&OpponentTeamID=0&VsConference=&VsDivision=&Position=&RookieYear=&GameSegment=&Period=0&LastNGames=0&ContextFilter=&ContextMeasure=FG_PCT&display-mode=performance&zone-mode=zone"
##all teams all years
for(i in 1:30) {
for(j in 19:19) {
url <- paste(urlbase1, YearIDs[j], urlbase2, TeamIDs[i,2], urlbase3, sep="")
print(url)
download.file(url, paste(TeamIDs[i,1], YearIDs[j], ".json", sep=""))
}
}
for(i in 1:30) {
teamdata<-matrix(0,ncol=21)
for(j in 19:19) {
filename <- paste(TeamIDs[i,1], YearIDs[j], ".json", sep="")
raw = fromJSON(readLines(filename))
shotdata <- lapply( raw, function(u) lapply(u, function(x) if(is.null(x)) NA else x))
shotdata<-shotdata[[3]]
data2<-shotdata[[1]][[3]]
if(length(data2)==0){
next()}
data <- matrix( nrow=length(data2), ncol=21)
for(k in 1:length(data2)){
for(l in 1:21) {
if(length(data2[[k]][[l]]) == 1) {
data[k,l] <- data2[[k]][[l]]
}
}
}
data[,1]<-YearIDs[j]
colnames(data)<-c("Year","GameID","GameEventID","PlayerID","PlayerName","TeamID","TeamName","Period","MinutesRemaining",
"SecondsRemaining","ShotResult","ActionType","ShotType","ShotZoneBasic","ShotZoneArea","ShotZoneRange",
"ShotDistance","X.Coord","Y.Coord","ShotAttemptedDummy","ShotMadeDummy")
teamdata<-rbind(teamdata,data)
}
write.table(teamdata[-1,], file=paste("Shots",TeamIDs[i,1],".csv", sep=""), sep=",",row.names=FALSE)
}
View(teamdata)
for(file in list.files("csv")){
a<-read.csv(paste("csv/",file,sep=""))
b<-rbind(b,a)
}
write.table(b,file="full/new.csv",sep=",")
for(i in 1:length(x)){
colClasses<-c(colClasses,x[[i]])
}
for(file in list.files("csv")){
a<-read.csv(paste("csv/",file,sep=""))
b<-rbind(b,a)
}
write.table(b,file="full/new.csv",sep=",")
View(teamdata)
teamdata[teamdata$TeamName="Houston Rockets"]
teamdata[teamdata$TeamName=="Houston Rockets"]
teamdata[teamdata$TeamName==="Houston Rockets"]
View(a)
for(file in list.files("csv")){
a<-read.csv(paste("csv/",file,sep=""))
b<-rbind(b,a)
}
View(a)
getwd()
setwd("/Users/bn/nba2014")
for(file in list.files("csv")){
a<-read.csv(paste("csv/",file,sep=""))
b<-rbind(b,a)
}
View(a)
View(a)
View(a)
delete(a)
a<-0
for(file in list.files("csv")){
a<-read.csv(paste("csv/",file,sep=""))
b<-rbind(b,a)
}
?list.files
getwd()
for(file in list.files("csv")){
a<-read.csv(paste("csv/",file,sep=""))
}
for(file in list.files("csv")){
print(file)
}
view(file)
for(file in list.files(".csv")){
print(file)
}
for(file in list.files()){
print(file)
}
for(file in list.files()){
a<-read.csv(paste("csv/",file,sep=""))
b<-rbind(b,a)
}
hou<-read.csv("shotsHou.csv")
View(hou)
hou$playername
hou$PlayerName
unique(hou$PlayerName)
runApp("shinyapp")
runApp("/shinyapp")
getwd()
setwd(/users/bn")
setwd("/users/bn")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
unique(hou$PlayerName)
as.character(unique(hou$PlayerName))
names(unique(hou$PlayerName))
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
install.packages("png")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
install.packages(c("boot", "BradleyTerry2", "class", "KernSmooth", "nnet", "rpart", "spatial", "tseries"))
install_github('slidify','ramnathv')
library("devtools", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install_github('slidify','ramnathv')
install_github('ramnathv/slidifyLibraries')
library(slidify)
getwd()
setwd("/users/bn/slidify")
setwd("/users/bn/slidify")
author("shotchart")
slidify("index.rmd")
slidify("index.rmd")
slidify("index.rmd")
